{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcded3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import math\n",
    "import plotly.express as px\n",
    "import dateutil.relativedelta\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def create_df(df,steps=1):\n",
    "    \n",
    "    dataX,dataY = [],[]\n",
    "    \n",
    "    for i in range(len(df)-steps-1):\n",
    "        a = df[i:(i+steps),0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(df[i+steps,0])\n",
    "    return np.array(dataX),np.array(dataY)\n",
    "\n",
    "\n",
    "def prever_valor_lstm(array,dias_anteriores,dias_previsao,epocas):\n",
    "\n",
    "    if len(array) < 130:\n",
    "        dias_anteriores = 10\n",
    "        \n",
    "    \n",
    "    dias_retorno = dias_anteriores\n",
    "    \n",
    "    dias_previsao = dias_previsao\n",
    "    \n",
    "\n",
    "    qtd_linhas = len(array)\n",
    "\n",
    "    qtd_linhas_treino = round(.70*qtd_linhas)\n",
    "\n",
    "\n",
    "    qtd_linhas_teste = qtd_linhas-qtd_linhas_treino\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(array)\n",
    "\n",
    "    #Separa em treino e teste\n",
    "\n",
    "    train = df_scaled[:qtd_linhas_treino]\n",
    "    test = df_scaled[qtd_linhas_treino:qtd_linhas_treino+qtd_linhas_teste]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #gerando dados de treino e de teste\n",
    "\n",
    "    steps = dias_retorno\n",
    "\n",
    "    X_train,Y_train = create_df(train,steps)\n",
    "    X_teste,Y_teste = create_df(test,steps)\n",
    "    \n",
    "    \n",
    "    if(len(X_train)>0):\n",
    "\n",
    "        #print('Treino x: ',X_train.shape,' Treino y: ',Y_train.shape)\n",
    "        #print('Teste x: ',X_teste.shape,' Teste y: ',Y_teste.shape)\n",
    "\n",
    "        \"\"\"Esse 1 significa a quantidade de features o modelo tem\"\"\"\n",
    "        X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "        X_teste = X_teste.reshape(X_teste.shape[0],X_teste.shape[1],1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #montando a rede\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(35,return_sequences=True,input_shape=(steps,1)))\n",
    "        model.add(LSTM(35,return_sequences=True))\n",
    "        model.add(LSTM(35))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1))\n",
    "\n",
    "        model.compile(optimizer='adam',loss='mse')\n",
    "        #model.summary()\n",
    "\n",
    "        validation = model.fit(X_train,Y_train,validation_data=(X_teste,Y_teste),epochs=epocas,batch_size=dias_retorno,verbose=2)\n",
    "        \n",
    "        length_test = len(test)\n",
    "\n",
    "        days_input_steps = length_test - steps\n",
    "        #print(\"Tamanho do test: \",length_test)\n",
    "        #print(\"Quantidade de dias retornados: \",days_input_steps)\n",
    "\n",
    "        input_steps = test[days_input_steps:]\n",
    "        input_steps = np.array(input_steps).reshape(1,-1)\n",
    "        #input_steps\n",
    "\n",
    "        #Transformar em lista\n",
    "        list_output_steps = list(input_steps)\n",
    "        list_output_steps = list_output_steps[0].tolist()\n",
    "        #list_output_steps\n",
    "\n",
    "        pred_output =[]\n",
    "        i = 0\n",
    "        n_future = 1\n",
    "\n",
    "        while(i<n_future):\n",
    "            if(len(list_output_steps)>steps):\n",
    "                input_steps = np.array(list_output_steps[1:])\n",
    "                #print(\"{} dia. Valores de entrada -> {}\".format(i,input_steps))\n",
    "                input_steps = input_steps.reshape(1,-1)\n",
    "                input_steps = input_steps.reshape((1,steps,1))\n",
    "                pred = model.predict(input_steps,verbose=0)\n",
    "                #print(\"{} dia. Valor previsto {}\".format(i,pred))\n",
    "                list_output_steps.extend(pred[0].tolist())\n",
    "                list_output_steps = list_output_steps[1:]\n",
    "                pred_output.extend(pred.tolist())\n",
    "                i=i+1\n",
    "            else:\n",
    "                input_steps = input_steps.reshape((1,steps,1))\n",
    "                pred = model.predict(input_steps, verbose=0)\n",
    "                #print(pred[0])\n",
    "                list_output_steps.extend(pred[0].tolist())\n",
    "                #print(len(list_output_steps))\n",
    "                pred_output.extend(pred.tolist())\n",
    "                i=i+1\n",
    "\n",
    "        #print(pred_output)\n",
    "\n",
    "        prev = scaler.inverse_transform(pred_output)\n",
    "        prev = np.array(prev).reshape(1,-1)\n",
    "        #proxima_alta = list(prev)\n",
    "        proxima_alta = prev[0].tolist()\n",
    "\n",
    "    return proxima_alta    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827182a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead68891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fd4ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac09d9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = \"PRIO3.SA\"\n",
    "acao = yf.download(ticker)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(acao[:\"2022-11-21\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fb02a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e145805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87f073f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a18fe703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "523/523 - 10s - loss: 0.0780 - val_loss: 0.0144 - 10s/epoch - 19ms/step\n",
      "Epoch 2/100\n",
      "523/523 - 3s - loss: 0.0166 - val_loss: 0.0106 - 3s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "523/523 - 3s - loss: 0.0186 - val_loss: 0.0173 - 3s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "523/523 - 3s - loss: 0.0138 - val_loss: 0.0170 - 3s/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "523/523 - 3s - loss: 0.0156 - val_loss: 0.0098 - 3s/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "523/523 - 3s - loss: 0.0150 - val_loss: 0.0083 - 3s/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "523/523 - 3s - loss: 0.0138 - val_loss: 0.0083 - 3s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "523/523 - 3s - loss: 0.0154 - val_loss: 0.0263 - 3s/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "523/523 - 3s - loss: 0.0141 - val_loss: 0.0137 - 3s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "523/523 - 3s - loss: 0.0144 - val_loss: 0.0077 - 3s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "523/523 - 3s - loss: 0.0123 - val_loss: 0.0077 - 3s/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "523/523 - 3s - loss: 0.0125 - val_loss: 0.0149 - 3s/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "523/523 - 3s - loss: 0.0142 - val_loss: 0.0084 - 3s/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "523/523 - 3s - loss: 0.0141 - val_loss: 0.0107 - 3s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "523/523 - 3s - loss: 0.0125 - val_loss: 0.0074 - 3s/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "523/523 - 3s - loss: 0.0136 - val_loss: 0.0092 - 3s/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "523/523 - 3s - loss: 0.0117 - val_loss: 0.0248 - 3s/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "523/523 - 3s - loss: 0.0130 - val_loss: 0.0062 - 3s/epoch - 6ms/step\n",
      "Epoch 19/100\n",
      "523/523 - 3s - loss: 0.0127 - val_loss: 0.0204 - 3s/epoch - 6ms/step\n",
      "Epoch 20/100\n",
      "523/523 - 3s - loss: 0.0117 - val_loss: 0.0125 - 3s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "523/523 - 3s - loss: 0.0134 - val_loss: 0.0075 - 3s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "523/523 - 3s - loss: 0.0108 - val_loss: 0.0073 - 3s/epoch - 6ms/step\n",
      "Epoch 23/100\n",
      "523/523 - 3s - loss: 0.0119 - val_loss: 0.0069 - 3s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "523/523 - 3s - loss: 0.0115 - val_loss: 0.0076 - 3s/epoch - 6ms/step\n",
      "Epoch 25/100\n",
      "523/523 - 3s - loss: 0.0117 - val_loss: 0.0059 - 3s/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "523/523 - 3s - loss: 0.0122 - val_loss: 0.0055 - 3s/epoch - 6ms/step\n",
      "Epoch 27/100\n",
      "523/523 - 3s - loss: 0.0119 - val_loss: 0.0076 - 3s/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "523/523 - 3s - loss: 0.0094 - val_loss: 0.0066 - 3s/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "523/523 - 3s - loss: 0.0132 - val_loss: 0.0038 - 3s/epoch - 7ms/step\n",
      "Epoch 30/100\n",
      "523/523 - 3s - loss: 0.0107 - val_loss: 0.0147 - 3s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "523/523 - 3s - loss: 0.0119 - val_loss: 0.0038 - 3s/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "523/523 - 3s - loss: 0.0119 - val_loss: 0.0050 - 3s/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "523/523 - 3s - loss: 0.0103 - val_loss: 0.0038 - 3s/epoch - 6ms/step\n",
      "Epoch 34/100\n",
      "523/523 - 3s - loss: 0.0112 - val_loss: 0.0040 - 3s/epoch - 6ms/step\n",
      "Epoch 35/100\n",
      "523/523 - 3s - loss: 0.0112 - val_loss: 0.0044 - 3s/epoch - 6ms/step\n",
      "Epoch 36/100\n",
      "523/523 - 3s - loss: 0.0105 - val_loss: 0.0068 - 3s/epoch - 6ms/step\n",
      "Epoch 37/100\n",
      "523/523 - 3s - loss: 0.0103 - val_loss: 0.0184 - 3s/epoch - 6ms/step\n",
      "Epoch 38/100\n",
      "523/523 - 3s - loss: 0.0115 - val_loss: 0.0098 - 3s/epoch - 6ms/step\n",
      "Epoch 39/100\n",
      "523/523 - 3s - loss: 0.0104 - val_loss: 0.0039 - 3s/epoch - 6ms/step\n",
      "Epoch 40/100\n",
      "523/523 - 3s - loss: 0.0097 - val_loss: 0.0048 - 3s/epoch - 6ms/step\n",
      "Epoch 41/100\n",
      "523/523 - 3s - loss: 0.0102 - val_loss: 0.0040 - 3s/epoch - 6ms/step\n",
      "Epoch 42/100\n",
      "523/523 - 3s - loss: 0.0108 - val_loss: 0.0036 - 3s/epoch - 6ms/step\n",
      "Epoch 43/100\n",
      "523/523 - 3s - loss: 0.0112 - val_loss: 0.0055 - 3s/epoch - 6ms/step\n",
      "Epoch 44/100\n",
      "523/523 - 3s - loss: 0.0110 - val_loss: 0.0059 - 3s/epoch - 6ms/step\n",
      "Epoch 45/100\n",
      "523/523 - 3s - loss: 0.0095 - val_loss: 0.0069 - 3s/epoch - 6ms/step\n",
      "Epoch 46/100\n",
      "523/523 - 3s - loss: 0.0094 - val_loss: 0.0186 - 3s/epoch - 6ms/step\n",
      "Epoch 47/100\n",
      "523/523 - 3s - loss: 0.0104 - val_loss: 0.0045 - 3s/epoch - 6ms/step\n",
      "Epoch 48/100\n",
      "523/523 - 3s - loss: 0.0098 - val_loss: 0.0082 - 3s/epoch - 6ms/step\n",
      "Epoch 49/100\n",
      "523/523 - 3s - loss: 0.0097 - val_loss: 0.0117 - 3s/epoch - 6ms/step\n",
      "Epoch 50/100\n",
      "523/523 - 3s - loss: 0.0102 - val_loss: 0.0088 - 3s/epoch - 6ms/step\n",
      "Epoch 51/100\n",
      "523/523 - 3s - loss: 0.0099 - val_loss: 0.0052 - 3s/epoch - 6ms/step\n",
      "Epoch 52/100\n",
      "523/523 - 3s - loss: 0.0106 - val_loss: 0.0172 - 3s/epoch - 6ms/step\n",
      "Epoch 53/100\n",
      "523/523 - 3s - loss: 0.0100 - val_loss: 0.0050 - 3s/epoch - 6ms/step\n",
      "Epoch 54/100\n",
      "523/523 - 3s - loss: 0.0114 - val_loss: 0.0036 - 3s/epoch - 6ms/step\n",
      "Epoch 55/100\n",
      "523/523 - 3s - loss: 0.0097 - val_loss: 0.0052 - 3s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "523/523 - 3s - loss: 0.0091 - val_loss: 0.0036 - 3s/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "523/523 - 3s - loss: 0.0102 - val_loss: 0.0088 - 3s/epoch - 6ms/step\n",
      "Epoch 58/100\n",
      "523/523 - 3s - loss: 0.0105 - val_loss: 0.0055 - 3s/epoch - 6ms/step\n",
      "Epoch 59/100\n",
      "523/523 - 3s - loss: 0.0092 - val_loss: 0.0317 - 3s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "523/523 - 3s - loss: 0.0091 - val_loss: 0.0067 - 3s/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "523/523 - 4s - loss: 0.0092 - val_loss: 0.0043 - 4s/epoch - 7ms/step\n",
      "Epoch 62/100\n",
      "523/523 - 4s - loss: 0.0099 - val_loss: 0.0045 - 4s/epoch - 7ms/step\n",
      "Epoch 63/100\n",
      "523/523 - 4s - loss: 0.0125 - val_loss: 0.0056 - 4s/epoch - 7ms/step\n",
      "Epoch 64/100\n",
      "523/523 - 4s - loss: 0.0106 - val_loss: 0.0073 - 4s/epoch - 7ms/step\n",
      "Epoch 65/100\n",
      "523/523 - 3s - loss: 0.0106 - val_loss: 0.0051 - 3s/epoch - 7ms/step\n",
      "Epoch 66/100\n",
      "523/523 - 4s - loss: 0.0106 - val_loss: 0.0070 - 4s/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "523/523 - 3s - loss: 0.0087 - val_loss: 0.0048 - 3s/epoch - 7ms/step\n",
      "Epoch 68/100\n",
      "523/523 - 3s - loss: 0.0112 - val_loss: 0.0036 - 3s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "523/523 - 4s - loss: 0.0095 - val_loss: 0.0069 - 4s/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "523/523 - 3s - loss: 0.0096 - val_loss: 0.0086 - 3s/epoch - 7ms/step\n",
      "Epoch 71/100\n",
      "523/523 - 4s - loss: 0.0089 - val_loss: 0.0096 - 4s/epoch - 7ms/step\n",
      "Epoch 72/100\n",
      "523/523 - 3s - loss: 0.0093 - val_loss: 0.0032 - 3s/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "523/523 - 3s - loss: 0.0115 - val_loss: 0.0033 - 3s/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "523/523 - 3s - loss: 0.0106 - val_loss: 0.0050 - 3s/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "523/523 - 4s - loss: 0.0100 - val_loss: 0.0036 - 4s/epoch - 7ms/step\n",
      "Epoch 76/100\n",
      "523/523 - 4s - loss: 0.0090 - val_loss: 0.0054 - 4s/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "523/523 - 4s - loss: 0.0094 - val_loss: 0.0074 - 4s/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "523/523 - 3s - loss: 0.0095 - val_loss: 0.0036 - 3s/epoch - 7ms/step\n",
      "Epoch 79/100\n",
      "523/523 - 4s - loss: 0.0111 - val_loss: 0.0045 - 4s/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "523/523 - 3s - loss: 0.0109 - val_loss: 0.0141 - 3s/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "523/523 - 4s - loss: 0.0095 - val_loss: 0.0036 - 4s/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "523/523 - 3s - loss: 0.0114 - val_loss: 0.0068 - 3s/epoch - 7ms/step\n",
      "Epoch 83/100\n",
      "523/523 - 4s - loss: 0.0089 - val_loss: 0.0060 - 4s/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "523/523 - 4s - loss: 0.0090 - val_loss: 0.0035 - 4s/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "523/523 - 3s - loss: 0.0093 - val_loss: 0.0038 - 3s/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "523/523 - 3s - loss: 0.0109 - val_loss: 0.0083 - 3s/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "523/523 - 4s - loss: 0.0097 - val_loss: 0.0037 - 4s/epoch - 7ms/step\n",
      "Epoch 88/100\n",
      "523/523 - 4s - loss: 0.0094 - val_loss: 0.0046 - 4s/epoch - 7ms/step\n",
      "Epoch 89/100\n",
      "523/523 - 3s - loss: 0.0099 - val_loss: 0.0040 - 3s/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "523/523 - 4s - loss: 0.0103 - val_loss: 0.0037 - 4s/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "523/523 - 4s - loss: 0.0100 - val_loss: 0.0037 - 4s/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "523/523 - 4s - loss: 0.0105 - val_loss: 0.0048 - 4s/epoch - 7ms/step\n",
      "Epoch 93/100\n",
      "523/523 - 4s - loss: 0.0077 - val_loss: 0.0050 - 4s/epoch - 7ms/step\n",
      "Epoch 94/100\n",
      "523/523 - 4s - loss: 0.0098 - val_loss: 0.0033 - 4s/epoch - 7ms/step\n",
      "Epoch 95/100\n",
      "523/523 - 4s - loss: 0.0087 - val_loss: 0.0046 - 4s/epoch - 7ms/step\n",
      "Epoch 96/100\n",
      "523/523 - 3s - loss: 0.0083 - val_loss: 0.0036 - 3s/epoch - 7ms/step\n",
      "Epoch 97/100\n",
      "523/523 - 3s - loss: 0.0098 - val_loss: 0.0051 - 3s/epoch - 7ms/step\n",
      "Epoch 98/100\n",
      "523/523 - 3s - loss: 0.0081 - val_loss: 0.0052 - 3s/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "523/523 - 3s - loss: 0.0098 - val_loss: 0.0123 - 3s/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "523/523 - 4s - loss: 0.0092 - val_loss: 0.0092 - 4s/epoch - 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "523/523 - 10s - loss: 0.0613 - val_loss: 0.0166 - 10s/epoch - 18ms/step\n",
      "Epoch 2/100\n",
      "523/523 - 3s - loss: 0.0179 - val_loss: 0.0221 - 3s/epoch - 6ms/step\n",
      "Epoch 3/100\n",
      "523/523 - 3s - loss: 0.0167 - val_loss: 0.0172 - 3s/epoch - 6ms/step\n",
      "Epoch 4/100\n",
      "523/523 - 3s - loss: 0.0155 - val_loss: 0.0100 - 3s/epoch - 6ms/step\n",
      "Epoch 5/100\n",
      "523/523 - 3s - loss: 0.0166 - val_loss: 0.0109 - 3s/epoch - 6ms/step\n",
      "Epoch 6/100\n",
      "523/523 - 3s - loss: 0.0145 - val_loss: 0.0193 - 3s/epoch - 6ms/step\n",
      "Epoch 7/100\n",
      "523/523 - 3s - loss: 0.0150 - val_loss: 0.0131 - 3s/epoch - 6ms/step\n",
      "Epoch 8/100\n",
      "523/523 - 3s - loss: 0.0143 - val_loss: 0.0146 - 3s/epoch - 6ms/step\n",
      "Epoch 9/100\n",
      "523/523 - 3s - loss: 0.0118 - val_loss: 0.0133 - 3s/epoch - 6ms/step\n",
      "Epoch 10/100\n",
      "523/523 - 3s - loss: 0.0135 - val_loss: 0.0175 - 3s/epoch - 6ms/step\n",
      "Epoch 11/100\n",
      "523/523 - 3s - loss: 0.0165 - val_loss: 0.0081 - 3s/epoch - 6ms/step\n",
      "Epoch 12/100\n",
      "523/523 - 3s - loss: 0.0129 - val_loss: 0.0075 - 3s/epoch - 6ms/step\n",
      "Epoch 13/100\n",
      "523/523 - 3s - loss: 0.0118 - val_loss: 0.0100 - 3s/epoch - 6ms/step\n",
      "Epoch 14/100\n",
      "523/523 - 3s - loss: 0.0131 - val_loss: 0.0168 - 3s/epoch - 6ms/step\n",
      "Epoch 15/100\n",
      "523/523 - 3s - loss: 0.0125 - val_loss: 0.0086 - 3s/epoch - 6ms/step\n",
      "Epoch 16/100\n",
      "523/523 - 3s - loss: 0.0108 - val_loss: 0.0083 - 3s/epoch - 6ms/step\n",
      "Epoch 17/100\n",
      "523/523 - 3s - loss: 0.0117 - val_loss: 0.0105 - 3s/epoch - 6ms/step\n",
      "Epoch 18/100\n",
      "523/523 - 3s - loss: 0.0121 - val_loss: 0.0062 - 3s/epoch - 7ms/step\n",
      "Epoch 19/100\n",
      "523/523 - 4s - loss: 0.0128 - val_loss: 0.0292 - 4s/epoch - 8ms/step\n",
      "Epoch 20/100\n",
      "523/523 - 3s - loss: 0.0117 - val_loss: 0.0058 - 3s/epoch - 6ms/step\n",
      "Epoch 21/100\n",
      "523/523 - 3s - loss: 0.0109 - val_loss: 0.0093 - 3s/epoch - 6ms/step\n",
      "Epoch 22/100\n",
      "523/523 - 3s - loss: 0.0120 - val_loss: 0.0086 - 3s/epoch - 7ms/step\n",
      "Epoch 23/100\n",
      "523/523 - 3s - loss: 0.0124 - val_loss: 0.0077 - 3s/epoch - 6ms/step\n",
      "Epoch 24/100\n",
      "523/523 - 3s - loss: 0.0111 - val_loss: 0.0135 - 3s/epoch - 7ms/step\n",
      "Epoch 25/100\n",
      "523/523 - 3s - loss: 0.0099 - val_loss: 0.0058 - 3s/epoch - 6ms/step\n",
      "Epoch 26/100\n",
      "523/523 - 4s - loss: 0.0112 - val_loss: 0.0053 - 4s/epoch - 7ms/step\n",
      "Epoch 27/100\n",
      "523/523 - 3s - loss: 0.0109 - val_loss: 0.0116 - 3s/epoch - 6ms/step\n",
      "Epoch 28/100\n",
      "523/523 - 3s - loss: 0.0113 - val_loss: 0.0052 - 3s/epoch - 6ms/step\n",
      "Epoch 29/100\n",
      "523/523 - 3s - loss: 0.0104 - val_loss: 0.0054 - 3s/epoch - 6ms/step\n",
      "Epoch 30/100\n",
      "523/523 - 3s - loss: 0.0112 - val_loss: 0.0039 - 3s/epoch - 6ms/step\n",
      "Epoch 31/100\n",
      "523/523 - 3s - loss: 0.0118 - val_loss: 0.0045 - 3s/epoch - 6ms/step\n",
      "Epoch 32/100\n",
      "523/523 - 3s - loss: 0.0088 - val_loss: 0.0048 - 3s/epoch - 6ms/step\n",
      "Epoch 33/100\n",
      "523/523 - 4s - loss: 0.0089 - val_loss: 0.0052 - 4s/epoch - 7ms/step\n",
      "Epoch 34/100\n",
      "523/523 - 4s - loss: 0.0099 - val_loss: 0.0049 - 4s/epoch - 8ms/step\n",
      "Epoch 35/100\n",
      "523/523 - 3s - loss: 0.0104 - val_loss: 0.0173 - 3s/epoch - 7ms/step\n",
      "Epoch 36/100\n",
      "523/523 - 4s - loss: 0.0089 - val_loss: 0.0223 - 4s/epoch - 7ms/step\n",
      "Epoch 37/100\n",
      "523/523 - 4s - loss: 0.0109 - val_loss: 0.0050 - 4s/epoch - 7ms/step\n",
      "Epoch 38/100\n",
      "523/523 - 4s - loss: 0.0096 - val_loss: 0.0126 - 4s/epoch - 7ms/step\n",
      "Epoch 39/100\n",
      "523/523 - 4s - loss: 0.0101 - val_loss: 0.0044 - 4s/epoch - 8ms/step\n",
      "Epoch 40/100\n",
      "523/523 - 4s - loss: 0.0099 - val_loss: 0.0039 - 4s/epoch - 7ms/step\n",
      "Epoch 41/100\n",
      "523/523 - 4s - loss: 0.0100 - val_loss: 0.0039 - 4s/epoch - 7ms/step\n",
      "Epoch 42/100\n",
      "523/523 - 4s - loss: 0.0106 - val_loss: 0.0042 - 4s/epoch - 8ms/step\n",
      "Epoch 43/100\n",
      "523/523 - 4s - loss: 0.0103 - val_loss: 0.0042 - 4s/epoch - 7ms/step\n",
      "Epoch 44/100\n",
      "523/523 - 4s - loss: 0.0099 - val_loss: 0.0074 - 4s/epoch - 7ms/step\n",
      "Epoch 45/100\n",
      "523/523 - 4s - loss: 0.0091 - val_loss: 0.0073 - 4s/epoch - 7ms/step\n",
      "Epoch 46/100\n",
      "523/523 - 4s - loss: 0.0112 - val_loss: 0.0092 - 4s/epoch - 8ms/step\n",
      "Epoch 47/100\n",
      "523/523 - 4s - loss: 0.0105 - val_loss: 0.0035 - 4s/epoch - 7ms/step\n",
      "Epoch 48/100\n",
      "523/523 - 4s - loss: 0.0100 - val_loss: 0.0050 - 4s/epoch - 8ms/step\n",
      "Epoch 49/100\n",
      "523/523 - 4s - loss: 0.0110 - val_loss: 0.0066 - 4s/epoch - 7ms/step\n",
      "Epoch 50/100\n",
      "523/523 - 4s - loss: 0.0089 - val_loss: 0.0049 - 4s/epoch - 7ms/step\n",
      "Epoch 51/100\n",
      "523/523 - 4s - loss: 0.0115 - val_loss: 0.0041 - 4s/epoch - 7ms/step\n",
      "Epoch 52/100\n",
      "523/523 - 4s - loss: 0.0081 - val_loss: 0.0039 - 4s/epoch - 7ms/step\n",
      "Epoch 53/100\n",
      "523/523 - 4s - loss: 0.0090 - val_loss: 0.0080 - 4s/epoch - 7ms/step\n",
      "Epoch 54/100\n",
      "523/523 - 4s - loss: 0.0085 - val_loss: 0.0135 - 4s/epoch - 7ms/step\n",
      "Epoch 55/100\n",
      "523/523 - 3s - loss: 0.0093 - val_loss: 0.0034 - 3s/epoch - 6ms/step\n",
      "Epoch 56/100\n",
      "523/523 - 3s - loss: 0.0100 - val_loss: 0.0054 - 3s/epoch - 6ms/step\n",
      "Epoch 57/100\n",
      "523/523 - 3s - loss: 0.0092 - val_loss: 0.0070 - 3s/epoch - 7ms/step\n",
      "Epoch 58/100\n",
      "523/523 - 4s - loss: 0.0094 - val_loss: 0.0053 - 4s/epoch - 8ms/step\n",
      "Epoch 59/100\n",
      "523/523 - 3s - loss: 0.0097 - val_loss: 0.0162 - 3s/epoch - 6ms/step\n",
      "Epoch 60/100\n",
      "523/523 - 3s - loss: 0.0094 - val_loss: 0.0043 - 3s/epoch - 6ms/step\n",
      "Epoch 61/100\n",
      "523/523 - 3s - loss: 0.0096 - val_loss: 0.0037 - 3s/epoch - 6ms/step\n",
      "Epoch 62/100\n",
      "523/523 - 3s - loss: 0.0101 - val_loss: 0.0034 - 3s/epoch - 6ms/step\n",
      "Epoch 63/100\n",
      "523/523 - 3s - loss: 0.0092 - val_loss: 0.0097 - 3s/epoch - 6ms/step\n",
      "Epoch 64/100\n",
      "523/523 - 3s - loss: 0.0101 - val_loss: 0.0074 - 3s/epoch - 6ms/step\n",
      "Epoch 65/100\n",
      "523/523 - 3s - loss: 0.0097 - val_loss: 0.0039 - 3s/epoch - 6ms/step\n",
      "Epoch 66/100\n",
      "523/523 - 3s - loss: 0.0102 - val_loss: 0.0042 - 3s/epoch - 7ms/step\n",
      "Epoch 67/100\n",
      "523/523 - 4s - loss: 0.0101 - val_loss: 0.0037 - 4s/epoch - 8ms/step\n",
      "Epoch 68/100\n",
      "523/523 - 4s - loss: 0.0091 - val_loss: 0.0035 - 4s/epoch - 7ms/step\n",
      "Epoch 69/100\n",
      "523/523 - 4s - loss: 0.0117 - val_loss: 0.0050 - 4s/epoch - 7ms/step\n",
      "Epoch 70/100\n",
      "523/523 - 4s - loss: 0.0088 - val_loss: 0.0046 - 4s/epoch - 8ms/step\n",
      "Epoch 71/100\n",
      "523/523 - 4s - loss: 0.0093 - val_loss: 0.0088 - 4s/epoch - 8ms/step\n",
      "Epoch 72/100\n",
      "523/523 - 4s - loss: 0.0088 - val_loss: 0.0071 - 4s/epoch - 7ms/step\n",
      "Epoch 73/100\n",
      "523/523 - 4s - loss: 0.0102 - val_loss: 0.0177 - 4s/epoch - 7ms/step\n",
      "Epoch 74/100\n",
      "523/523 - 4s - loss: 0.0101 - val_loss: 0.0075 - 4s/epoch - 7ms/step\n",
      "Epoch 75/100\n",
      "523/523 - 4s - loss: 0.0093 - val_loss: 0.0131 - 4s/epoch - 8ms/step\n",
      "Epoch 76/100\n",
      "523/523 - 4s - loss: 0.0093 - val_loss: 0.0072 - 4s/epoch - 7ms/step\n",
      "Epoch 77/100\n",
      "523/523 - 4s - loss: 0.0090 - val_loss: 0.0038 - 4s/epoch - 7ms/step\n",
      "Epoch 78/100\n",
      "523/523 - 4s - loss: 0.0092 - val_loss: 0.0162 - 4s/epoch - 8ms/step\n",
      "Epoch 79/100\n",
      "523/523 - 4s - loss: 0.0113 - val_loss: 0.0050 - 4s/epoch - 7ms/step\n",
      "Epoch 80/100\n",
      "523/523 - 4s - loss: 0.0096 - val_loss: 0.0056 - 4s/epoch - 7ms/step\n",
      "Epoch 81/100\n",
      "523/523 - 4s - loss: 0.0090 - val_loss: 0.0107 - 4s/epoch - 7ms/step\n",
      "Epoch 82/100\n",
      "523/523 - 4s - loss: 0.0087 - val_loss: 0.0077 - 4s/epoch - 8ms/step\n",
      "Epoch 83/100\n",
      "523/523 - 4s - loss: 0.0090 - val_loss: 0.0041 - 4s/epoch - 7ms/step\n",
      "Epoch 84/100\n",
      "523/523 - 4s - loss: 0.0090 - val_loss: 0.0040 - 4s/epoch - 7ms/step\n",
      "Epoch 85/100\n",
      "523/523 - 4s - loss: 0.0093 - val_loss: 0.0065 - 4s/epoch - 7ms/step\n",
      "Epoch 86/100\n",
      "523/523 - 4s - loss: 0.0119 - val_loss: 0.0153 - 4s/epoch - 7ms/step\n",
      "Epoch 87/100\n",
      "523/523 - 4s - loss: 0.0093 - val_loss: 0.0126 - 4s/epoch - 8ms/step\n",
      "Epoch 88/100\n",
      "523/523 - 4s - loss: 0.0086 - val_loss: 0.0107 - 4s/epoch - 8ms/step\n",
      "Epoch 89/100\n",
      "523/523 - 4s - loss: 0.0077 - val_loss: 0.0043 - 4s/epoch - 7ms/step\n",
      "Epoch 90/100\n",
      "523/523 - 3s - loss: 0.0100 - val_loss: 0.0111 - 3s/epoch - 7ms/step\n",
      "Epoch 91/100\n",
      "523/523 - 3s - loss: 0.0088 - val_loss: 0.0113 - 3s/epoch - 7ms/step\n",
      "Epoch 92/100\n",
      "523/523 - 3s - loss: 0.0093 - val_loss: 0.0076 - 3s/epoch - 6ms/step\n",
      "Epoch 93/100\n",
      "523/523 - 3s - loss: 0.0089 - val_loss: 0.0033 - 3s/epoch - 6ms/step\n",
      "Epoch 94/100\n",
      "523/523 - 3s - loss: 0.0083 - val_loss: 0.0076 - 3s/epoch - 6ms/step\n",
      "Epoch 95/100\n",
      "523/523 - 3s - loss: 0.0080 - val_loss: 0.0058 - 3s/epoch - 6ms/step\n",
      "Epoch 96/100\n",
      "523/523 - 3s - loss: 0.0089 - val_loss: 0.0049 - 3s/epoch - 6ms/step\n",
      "Epoch 97/100\n",
      "523/523 - 3s - loss: 0.0091 - val_loss: 0.0078 - 3s/epoch - 6ms/step\n",
      "Epoch 98/100\n",
      "523/523 - 3s - loss: 0.0097 - val_loss: 0.0042 - 3s/epoch - 6ms/step\n",
      "Epoch 99/100\n",
      "523/523 - 3s - loss: 0.0084 - val_loss: 0.0112 - 3s/epoch - 6ms/step\n",
      "Epoch 100/100\n",
      "523/523 - 3s - loss: 0.0096 - val_loss: 0.0077 - 3s/epoch - 6ms/step\n"
     ]
    }
   ],
   "source": [
    "alta = prever_valor_lstm(pd.DataFrame(df[\"High\"]),4,1,100)\n",
    "baixa = prever_valor_lstm(pd.DataFrame(df[\"Low\"]),4,1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23344e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb98c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d7c569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-11-22 00:00:00-03:00</th>\n",
       "      <td>34.959999</td>\n",
       "      <td>35.990002</td>\n",
       "      <td>34.830002</td>\n",
       "      <td>35.470001</td>\n",
       "      <td>35.470001</td>\n",
       "      <td>13516800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-23 00:00:00-03:00</th>\n",
       "      <td>34.980000</td>\n",
       "      <td>35.250000</td>\n",
       "      <td>34.740002</td>\n",
       "      <td>35.130001</td>\n",
       "      <td>35.130001</td>\n",
       "      <td>510700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2022-11-22 00:00:00-03:00  34.959999  35.990002  34.830002  35.470001   \n",
       "2022-11-23 00:00:00-03:00  34.980000  35.250000  34.740002  35.130001   \n",
       "\n",
       "                           Adj Close    Volume  \n",
       "Date                                            \n",
       "2022-11-22 00:00:00-03:00  35.470001  13516800  \n",
       "2022-11-23 00:00:00-03:00  35.130001    510700  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acao.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fee4a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.41595863879792] [32.62994501544941]\n"
     ]
    }
   ],
   "source": [
    "print(alta,baixa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5551a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692a195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eadaef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78238c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae197cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa8e63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e95ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137d27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df013710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71b0615d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2010-10-25 00:00:00-02:00    24.400000\n",
       "2010-10-26 00:00:00-02:00    23.400000\n",
       "2010-10-27 00:00:00-02:00    23.200001\n",
       "2010-10-28 00:00:00-02:00    22.709999\n",
       "2010-10-29 00:00:00-02:00    22.900000\n",
       "                               ...    \n",
       "2022-11-11 00:00:00-03:00    38.299999\n",
       "2022-11-14 00:00:00-03:00    39.250000\n",
       "2022-11-16 00:00:00-03:00    38.650002\n",
       "2022-11-17 00:00:00-03:00    35.799999\n",
       "2022-11-18 00:00:00-03:00    36.450001\n",
       "Name: High, Length: 2995, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"High\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07df5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dec055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "076d9cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-10-25 00:00:00-02:00</th>\n",
       "      <td>24.100000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>22.100800</td>\n",
       "      <td>23.340000</td>\n",
       "      <td>23.340000</td>\n",
       "      <td>25180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-26 00:00:00-02:00</th>\n",
       "      <td>22.800200</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>7200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-27 00:00:00-02:00</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>23.200001</td>\n",
       "      <td>22.202400</td>\n",
       "      <td>22.700001</td>\n",
       "      <td>22.700001</td>\n",
       "      <td>3685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-28 00:00:00-02:00</th>\n",
       "      <td>22.709999</td>\n",
       "      <td>22.709999</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>2900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-10-29 00:00:00-02:00</th>\n",
       "      <td>22.600000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>22.400000</td>\n",
       "      <td>22.740000</td>\n",
       "      <td>22.740000</td>\n",
       "      <td>825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-16 00:00:00-03:00</th>\n",
       "      <td>38.570000</td>\n",
       "      <td>38.650002</td>\n",
       "      <td>35.340000</td>\n",
       "      <td>36.270000</td>\n",
       "      <td>36.270000</td>\n",
       "      <td>20821900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-17 00:00:00-03:00</th>\n",
       "      <td>35.209999</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>34.200001</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>35.799999</td>\n",
       "      <td>21667300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-18 00:00:00-03:00</th>\n",
       "      <td>36.099998</td>\n",
       "      <td>36.450001</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>18514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-21 00:00:00-03:00</th>\n",
       "      <td>34.330002</td>\n",
       "      <td>34.860001</td>\n",
       "      <td>32.860001</td>\n",
       "      <td>34.490002</td>\n",
       "      <td>34.490002</td>\n",
       "      <td>16010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-22 00:00:00-03:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.470001</td>\n",
       "      <td>35.470001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2997 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Date                                                                    \n",
       "2010-10-25 00:00:00-02:00  24.100000  24.400000  22.100800  23.340000   \n",
       "2010-10-26 00:00:00-02:00  22.800200  23.400000  22.500000  22.500000   \n",
       "2010-10-27 00:00:00-02:00  22.500000  23.200001  22.202400  22.700001   \n",
       "2010-10-28 00:00:00-02:00  22.709999  22.709999  22.100000  22.500000   \n",
       "2010-10-29 00:00:00-02:00  22.600000  22.900000  22.400000  22.740000   \n",
       "...                              ...        ...        ...        ...   \n",
       "2022-11-16 00:00:00-03:00  38.570000  38.650002  35.340000  36.270000   \n",
       "2022-11-17 00:00:00-03:00  35.209999  35.799999  34.200001  35.799999   \n",
       "2022-11-18 00:00:00-03:00  36.099998  36.450001  34.250000  34.500000   \n",
       "2022-11-21 00:00:00-03:00  34.330002  34.860001  32.860001  34.490002   \n",
       "2022-11-22 00:00:00-03:00   0.000000   0.000000   0.000000  35.470001   \n",
       "\n",
       "                           Adj Close    Volume  \n",
       "Date                                            \n",
       "2010-10-25 00:00:00-02:00  23.340000  25180000  \n",
       "2010-10-26 00:00:00-02:00  22.500000   7200000  \n",
       "2010-10-27 00:00:00-02:00  22.700001   3685000  \n",
       "2010-10-28 00:00:00-02:00  22.500000   2900000  \n",
       "2010-10-29 00:00:00-02:00  22.740000    825000  \n",
       "...                              ...       ...  \n",
       "2022-11-16 00:00:00-03:00  36.270000  20821900  \n",
       "2022-11-17 00:00:00-03:00  35.799999  21667300  \n",
       "2022-11-18 00:00:00-03:00  34.500000  18514800  \n",
       "2022-11-21 00:00:00-03:00  34.490002  16010300  \n",
       "2022-11-22 00:00:00-03:00  35.470001         0  \n",
       "\n",
       "[2997 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f790d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2b1956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48e4a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae726d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a160f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
